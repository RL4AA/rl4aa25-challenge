{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align: center; vertical-align: middle;\">\n",
    "    <span style=\"color: #B74F3D;\"> 3rd Reinforcement Learning for Autonomous Accelerators workshop tutorial</span>\n",
    "    <span style=\"color: #666666;\">: Beam Transverse Steering at ARES Linear Accelerator</span>\n",
    "</h1>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../img/rl4aa_logo.png\" alt=\"RL4AA Logo\" style=\"max-width: 100%; height: auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Getting started</h2>\n",
    "\n",
    "- You will need **Python 3.12 or higher** to run this code &#x2757;\n",
    "- You will require about **1 GB of free disk space** &#x2757;\n",
    "- Make sure you have Git installed in your terminal &#x2757;\n",
    "\n",
    "\n",
    "Start by cloning locally the repository of the tutorial by running this command in your terminal:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/RL4AA/rl4aa25-tutorial.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Installing virtual environment</h2>\n",
    "\n",
    "### Using Conda\n",
    "\n",
    "- If you don't have conda installed already, you can install the `miniconda` as [described here](https://docs.conda.io/projects/miniconda/en/latest/miniconda-install.html).\n",
    "- We recommend to install `miniconda` the day beforehand to avoid network overload during the tutorial &#x2757; &#x2757;\n",
    "\n",
    "Once `miniconda` is installed run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "This should create a virtual environment named `rl25-tutorial` and install the necessary packages inside.\n",
    "\n",
    "Afterwards, activate the environment using\n",
    "\n",
    "```bash\n",
    "conda activate rl25-tutorial\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Installing virtual environment</h2>\n",
    "\n",
    "### Using venv\n",
    "\n",
    "_If you don't have conda installed:_\n",
    "\n",
    "Alternatively, you can create the virtual env with\n",
    "\n",
    "```bash\n",
    "python3 -m venv rl-tutorial\n",
    "```\n",
    "\n",
    "and activate the env with `$ source <venv>/bin/activate` (bash) or `C:> <venv>/Scripts/activate.bat` (Windows)\n",
    "\n",
    "Then, install the packages with `pip` within the activated environment\n",
    "\n",
    "```bash\n",
    "python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Afterwards, you should be able to run the provided scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Check your installation</h2>\n",
    "If you set up your virtual environment correctly and is activated you should be able to run the next cell without any errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "from IPython.display import clear_output, display, Latex, HTML, Markdown\n",
    "\n",
    "from src.environments import ea\n",
    "from src.environments.ea_auxiliary import make_eval_env\n",
    "from src.utils import evaluate_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\"> ARES (Accelerator Research Experiment at SINBAD)</h2>\n",
    "\n",
    "ARES is an S-band radio frequency linac at the DESY Hamburg site equipped with a photoinjector and two independently driven traveling wave accelerating structures. The main research focus is the generation and characterization of sub-femtosecond electron bunches at relativistic particle energy. The generation of short electron bunches is of high interest for radiation generation, i.e. by free electron lasers.\n",
    "\n",
    "<img src=\"../img/ARES_layout.png\" style=\"width:100%; margin:auto;\"/>\n",
    "\n",
    "- **Final energy**: 100-155 MeV\n",
    "- **Bunch charge**: 0.01-200 pC\n",
    "- **Bunch length**: 30 fs - 1 ps\n",
    "- **Pulse repetition rate**: 1-50 Hz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">The accelerator problem we want to solve</h2>\n",
    "\n",
    "We would like to focus and center the electron beam on a diagnostic screen using corrector and quadrupole magnets\n",
    "\n",
    "<img src=\"../img/ares_magnets.png\" style=\"width:70%; margin:auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Formulating the RL problem</h2>\n",
    "<h3>Overview of our study case</h3>\n",
    "<img src=\"../img/ares_rl_problem.png\" style=\"width:70%; margin:auto;\"/>\n",
    "\n",
    "<h3 style=\"color:#038aa1;\">Discussion</h3>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$  Is the action space continuous or discrete? </p>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$  Is the problem fully observable or partially observable?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Formulating the RL problem</h2>\n",
    "<h3>Actions</h3>\n",
    "\n",
    "<div class=\"row\">\n",
    "    <div class=\"column\" style=\"width:60%;float:left\">\n",
    "        <p>In the ARES transverse tuning task we have 3 quadrupoles and 2 corrector magnets</p>\n",
    "        <p>The actions are:\n",
    "            <ul>\n",
    "            <li><b>Quadrupole magnet strength</b> $k_{1,2,3}$ $[1/m^2]$</li>\n",
    "            <li><b>Corrector deflection angle</b> $\\theta_\\mathrm{v, h}$ $[mrad]$ (vertical and horizontal</li>\n",
    "            </ul>\n",
    "        </p>\n",
    "        <p>In our control system we can set these derived values directly according the beam energy</p>\n",
    "        <p>$\\implies$ <code>actions</code> $=[k_{\\mathrm{Q1}},k_{\\mathrm{Q2}},\\theta_\\mathrm{CV},k_{\\mathrm{Q3}},\\theta_\\mathrm{CH}]$</p>\n",
    "            <p>is a 5-dimensional array</p>\n",
    "    </div>\n",
    "    <div class=\"column\" style=\"width:40%;float:right\">\n",
    "        <img src=\"../img/dipole.png\" style=\"width:50%; margin:auto;\"/>\n",
    "        <img src=\"../img/quads.png\" style=\"width:35%; margin:auto;\"/>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Formulating the RL problem</h2>\n",
    "<h3>Observation / state</h3>\n",
    "\n",
    "<div class=\"row\">\n",
    "    <div class=\"column\" style=\"width:50%;float:left\">\n",
    "        <p>Observation is the information an agent receives about the current state of the environment</p>\n",
    "        <p>It should provide enough information so that the agent can solve this problem.</p>\n",
    "        <p>The observation does not necessarily cover the entire (internal) state of the environment.</p>\n",
    "        <h3 style=\"color:#038aa1;\">Discussion</h3>\n",
    "        <p style=\"color:#038aa1;\"> $\\implies$ What should be included in the <code>observation</code>?  </p>\n",
    "        <p style=\"color:#038aa1;\"> $\\implies$ What can be observed in the simulation? </p>\n",
    "        <p style=\"color:#038aa1;\"> $\\implies$ What cannot be observed in the real world? </p>\n",
    "        <p style=\"color:#038aa1;\"> $\\implies$ How does this relate to the environment? </p>\n",
    "    </div>\n",
    "    <div class=\"column\" style=\"width:50%;float:right\">\n",
    "      <img src=\"../img/screen_2.png\" style=\"width:40%; margin:auto;\"/>\n",
    "      <p style=\"clear:both; font-size: small; text-align: center; margin-top:1em;\">\n",
    "          The screen is made from scintillating material and glows when hit by electrons</p>\n",
    "      <img src=\"../img/screen_1.png\" style=\"width:40%; margin:auto;\"/>\n",
    "      <p style=\"clear:both; font-size: small; text-align: center; margin-top:1em;\">The camera films the screen</p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Formulating the RL problem</h2>\n",
    "<h3> The environment's state</h3>\n",
    "\n",
    "The `state` can be fully described by with four components:\n",
    "\n",
    "- The **target beam**: the beam we want to achieve, our goal\n",
    "  - as a 4-dimensional array $b^\\mathrm{(t)}=[\\mu_x^{(\\mathrm{t})},\\sigma_x^{(\\mathrm{t})},\\mu_y^{(\\mathrm{t})},\\sigma_y^{(\\mathrm{t})}]$, where $\\mu$ denotes the position on the screen, $\\sigma$ denotes the beam size, and $t$ stands for \"target\".\n",
    "- The **incoming beam**: the beam that enters the EA upstream\n",
    "  - $I = [\\mu_x^{(\\mathrm{i})},\\sigma_x^{(\\mathrm{i})},\\mu_y^{(\\mathrm{i})},\\sigma_y^{(\\mathrm{i})},\\mu_{xp}^{(\\mathrm{i})},\\sigma_{xp}^{(\\mathrm{i})},\\mu_{yp}^{(\\mathrm{i})},\\sigma_{yp}^{(\\mathrm{i})},\\mu_s^{(\\mathrm{i})},\\sigma_s^{(\\mathrm{i})}]$, where $i$ stands for \"incoming\"\n",
    "- The **magnet strengths** and **deflection angles**\n",
    "  - $[k_{\\mathrm{Q1}},k_{\\mathrm{Q2}},\\theta_\\mathrm{CV},k_{\\mathrm{Q3}},\\theta_\\mathrm{CH}]$\n",
    "- The **transverse misalignments** of **quadrupoles** and the **diagnostic screen**\n",
    "  - $[m_{\\mathrm{Q1}}^{(\\mathrm{x})},m_{\\mathrm{Q1}}^{(\\mathrm{y})},m_{\\mathrm{Q2}}^{(\\mathrm{x})},m_{\\mathrm{Q2}}^{(\\mathrm{y})},m_{\\mathrm{Q3}}^{(\\mathrm{x})},m_{\\mathrm{Q3}}^{(\\mathrm{y})},m_{\\mathrm{S}}^{(\\mathrm{x})},m_{\\mathrm{S}}^{(\\mathrm{y})}]$\n",
    "\n",
    "<h3 style=\"color:#038aa1;\">Discussion</h3>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$ Do we (fully) know or can we observe the state of the environment?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Formulating the RL problem</h2>\n",
    "<h3> Our definition of observation</h3>\n",
    "\n",
    "The `observation` for this task consists of three components:\n",
    "\n",
    "- The **target beam**:  The desired beam, or the goal we aim to achieve.\n",
    "  - as a 4-dimensional array $b^\\mathrm{(t)}=[\\mu_x^{(\\mathrm{t})},\\sigma_x^{(\\mathrm{t})},\\mu_y^{(\\mathrm{t})},\\sigma_y^{(\\mathrm{t})}]$, where $\\mu$ represents the position on the screen, $\\sigma$ denotes the beam size, and $t$ refers to the \"target\".\n",
    "- The **current beam**: The beam currently in place.\n",
    "  - $b^\\mathrm{(c)}=[\\mu_x^{(\\mathrm{c})},\\sigma_x^{(\\mathrm{c})},\\mu_y^{(\\mathrm{c})},\\sigma_y^{(\\mathrm{c})}]$, where $c$ represents \"current\".\n",
    "- Magnet settings: The **magnet strengths** and **deflection angles**\n",
    "  - $[k_{\\mathrm{Q1}},k_{\\mathrm{Q2}},\\theta_\\mathrm{CV},k_{\\mathrm{Q3}},\\theta_\\mathrm{CH}]$\n",
    "\n",
    "<h3 style=\"color:#038aa1;\">Discussion</h3>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$ Does this observation definition satisfy the Markov property? That is, does the probability distribution for the next beam depend only on the current observation, or is it influenced by other state information?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Formulating the RL problem</h2>\n",
    "<h3>Goal and reward</h3>\n",
    "\n",
    "Our goal is divided into two tasks:\n",
    "\n",
    "1. **Steering** the beam to the desired position.\n",
    "2. **Focusing** the beam to the desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">About libraries for RL</h2>\n",
    "\n",
    "There are several libraries that provide pre-implemented RL algorithms and frameworks for creating environments. In this notebook, we use:\n",
    "\n",
    "- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/) for the RL algorithms\n",
    "- [Gymnasium](https://gymnasium.farama.org/) for the environment\n",
    "<img src=\"../img/rl_libraries.png\"  style=\"width:60%; margin:auto;\"/>\n",
    "<p style=\"clear:both; font-size: small; text-align: center; margin-top:1em;\">More info <a href=\"https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python\">here</a></p>\n",
    "\n",
    "\n",
    "**Note**:\n",
    "\n",
    "- Gymnasium is the successor of the [OpenAI Gym](https://www.gymlibrary.dev/).\n",
    "- Stable-baselines3 now has an early-stage JAX implementation [sbx](https://github.com/araffin/sbx)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Environment</h2>\n",
    "\n",
    "We take all the elements of the RL problem we previously defined and represent the tuning task as a `gym`-based environment, a standard library for RL tasks.\n",
    "\n",
    "A custom `gym.Env` consists of the following components:\n",
    "\n",
    "- **Initialization**: Sets up the environment and defines the `observation_space` and `action_space`\n",
    "- `reset` **method**: Resets the environment for a new episode and returns a 2-tuple `(observation, info)`\n",
    "- `step` **method**: Contains the core logic. It accepts an action, updates the environment state, generates a new observation, computes the reward, and returns a 5-tuple `(observation, reward, terminated, truncated, info)`.\n",
    "  - `terminated` Determines whether the episode should end based on the underlying MDP (e.g., goal reached, threshold exceeded)\n",
    "  - `truncated` Checks if the episode should be truncated due to conditions outside the MDP (e.g., time limits).\n",
    "- `render` **method**: Provides a visual representation of the environment (e.g., video or plots)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">An overview of this RL project</h2>\n",
    "<img src=\"../img/ares_ea_rl_technical_setup.png\"  style=\"width:100%; margin:auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">Code Directory Structure in RL4AA-2025 Repository</h2>\n",
    "\n",
    "<p> The RL4AA-2025 Git repository contains all the necessary code and configurations for running reinforcement learning (RL) and Gaussian Process Model Predictive Control (GP-MPC) experiments for the ARES-EA transverse tuning task. Below is an overview of the key directories and their contents:</p>\n",
    "\n",
    "- `src` Contains the source code for the RL environment and the GP-MPC controller\n",
    "  - `src/environments/ea` contains the gymnasium environment for the ARES-EA transverse tuning task\n",
    "  - `src/reward` contains files for the reward engineering (combination of rewards, transformation, ...)\n",
    "  - `src/wrappers` contains custom wrappers for the EA environment\n",
    "    - `src/wrappers/ea_mpc_episode_with_plotting` contains the wrapper for running GP-MPC (mainly it creates the visualization)\n",
    "  - `src/train` contains scripts to train a default PPO agent to solve the task (can be used as a benchmark for evaluating MPC controller)\n",
    "  - `src/gpmpc` contains the GP-MPC controller\n",
    "    - `src/gpmpc/control_object` implements the controller\n",
    "      - `gp_models` implements the GP model for modeling the transition of the environment\n",
    "      - `gp_mpc_controller` implements the controller\n",
    "    - `src/gpmpc/utils` contains utility functions for the GP-MPC controller\n",
    "- `data/trail.yaml` contains the pre-selected task configurations for evaluation\n",
    "- `config/` config files for running GP-MPC control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 style=\"color: #b51f2a\">The ARES Experimental Area (ARES-EA) Environment</h2>\n",
    "\n",
    "- We formulated the ARES-EA task as a `gym` environment, allowing our algorithm to easily interface with both the simulation and real machine backends as shown before.\n",
    "  \n",
    "- In this section, you will become familiar with the environment for beam focusing and positioning at the ARES accelerator.\n",
    "\n",
    "Important APIs:\n",
    "\n",
    "- `reset`: Resets the magnets to their initial values in both real and simulation cases. In the simulation, it also regenerates the incoming beam and (optionally) resets magnet misalignments.\n",
    "- `step`: Adjusts the magnets to new settings and observes the beam (either by running a simulation or observing the screen image in the real world)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align: center; width:100%;\">\n",
    "    <h1>The Power of Standard Optimizers </h1>\n",
    "</div>\n",
    "\n",
    "The Nelder-Mead optimizer is a widely used, derivative-free optimization algorithm, well-suited for solving complex problems where gradients are difficult or expensive to compute. It relies on a simplex of n + 1 points to explore the search space and iteratively converges towards an optimal solution. In the context of the ARES-AE beam control problem, the Nelder-Mead optimizer is applied to adjust the magnet settings, effectively steering the beam to desired positions and focusing it to the required size. Its robustness in handling non-linear, noisy objective functions makes it an effective method for this type of application, where precise control over the beam's trajectory is crucial.\n",
    "\n",
    "However, to leverage the power of this optimizer, we first need to establish a well-defined environment that accurately models the problem at hand. The environment plays a crucial role in providing the feedback necessary for optimization, and in our case, it serves as the foundation for beam focusing and positioning at the ARES accelerator.\n",
    "\n",
    "Before diving into control algorithms, it's important to set up the simulation, define the state and observation space, and ensure the environment provides meaningful feedback to an agent or controller. In our setup, the environment models the behavior of the electron beam as it passes through magnets and interacts with the diagnostic screen. By initializing the environment, we ensure that:\n",
    "\n",
    "- We define a clear optimization goal – aligning the observed beam parameters with the target beam.\n",
    "\n",
    "- We establish a reproducible testbed – allowing us to evaluate different control methods systematically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#038aa1;\">Set a target beam you want to achieve</h3>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$ Let's define the desired position $(\\mu_x, \\mu_y)$ and size $(\\sigma_x, \\sigma_y)$ of the beam on the screen</p>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$ Modify the <code>target_beam</code> parameters list below, where the order of the arguments is $[\\mu_x,\\sigma_x,\\mu_y,\\sigma_y]$</p>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$  Consider the screen dimensions ($\\pm$ 2e-3 m) when setting the target values</p>\n",
    "<p style=\"color:#038aa1;\"> $\\implies$ The target beam will be visually represented as a blue circle on the screen</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set EA configuration parameters path\n",
    "config_path = Path(\"../config/ea_eval_config.yaml\")\n",
    "\n",
    "# Load EA configuration parameters\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Create a EA environment\n",
    "env = make_eval_env(config, ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificy target beam parameters, adjust as desired\n",
    "target_beam = np.array([1e-3, 2e-4, 1e-3, 2e-4])\n",
    "\n",
    "env.target_beam_values = target_beam\n",
    "env.reset()  # Render one simulation frame\n",
    "\n",
    "# Visually inspect beam position\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.imshow(env.render())  # Plot the screen image\n",
    "# Let's improve the rendering to be the same as for RL4AA23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment\n",
    "env.reset()\n",
    "\n",
    "# Get beam difference based on mean absolute error (MAE)\n",
    "env.unwrapped.get_beam_difference(metric=\"mae\")\n",
    "\n",
    "# Visually inspect beam difference\n",
    "plt.imshow(env.unwrapped.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tackling  the ARES Experimental Area Beam Transverse Tuning Problem\n",
    "\n",
    "The objective is to implement a controller or optimization method capable of steering the observed electron beam $\\bf{b}$ towards the target beam parameters, $\\bf{b}'$.\n",
    "\n",
    "The difference between the observed and target beam parameters can be characterized by the mean absolute error (MAE):\n",
    "$$\n",
    "d_\\text{MAE} (\\bf{b}, \\bf{b}') = \\frac{1}{4} \\sum_{i=1}^{4} |\\bf{b}_i - \\bf{b}'_i|\n",
    "$$\n",
    "\n",
    "The algorithm is allowed to interact with the environment for a total of $T$ steps. ($T=200$ in this example)\n",
    "\n",
    "The performance of the method will be evaluated using the following metrics:\n",
    "\n",
    "- Best MAE achieved by the method: $\\min d_i, i=1,\\dots, T$\n",
    "- Cumulative MAE difference over the episode: $\\sum_{i=1}^{T} d_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Method using Standard Optimizer\n",
    "\n",
    "To help you get started, below we provide a simple example using the Nelder-Mead optimizer to demonstrate how to interact with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we provide the baseline Nelder-Mead simplex Method\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the env interaction in an objective function for optimization\n",
    "def objective(x):\n",
    "    env.step(x)\n",
    "    return env.unwrapped.get_beam_difference(metric=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the Environment\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# Select the \"magnets\" parameters as observations\n",
    "x0 = obs[4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify minimization procedure\n",
    "res = minimize(\n",
    "    objective,\n",
    "    x0,\n",
    "    method=\"nelder-mead\",\n",
    "    options={\n",
    "        \"xatol\": 1e-8,\n",
    "        \"disp\": True,\n",
    "        \"maxfev\": config[\"env_wrapper\"][\n",
    "            \"max_episode_steps\"\n",
    "        ],  # Maximum number of function evaluations\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look into the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting observations\n",
    "observations = env.get_wrapper_attr(\"observations\")\n",
    "\n",
    "# Run MAE evaluation\n",
    "evaluate_mae(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it is time to develop your own controller!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create a controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Ideas:\n",
    "\n",
    "In the challenge, \n",
    "\n",
    "- Have a utility function to prepare the basic env setup (should not be modified) (cheetah backend, magnet range, ...)\n",
    "  - The users can change the \n",
    "  - \n",
    "- Create a new env wrapper to log the necessary statistics for the evaluation, e.g.\n",
    "  - MAEs over steps\n",
    "  - Wall-time used for each step\n",
    "- Evaluation Script that runs the control on several tasks and save the results\n",
    "  - Use argparse to decide which tasks to load, we provide the `train_tasks` in the beginning\n",
    "  - In the end, we provide the `test_tasks` for the final evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
